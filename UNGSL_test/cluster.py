import numpy as np
import torch
from sklearn.cluster import KMeans
from torch_geometric.data import Data
from torch_geometric.utils import subgraph
#from UNGSL_test import data_loader
torch.manual_seed(42)
np.random.seed(42)
def create_cluster(data, k=4):
    # ç¡®ä¿ train_mask æ˜¯ PyTorch Tensor
    if isinstance(data.train_mask, np.ndarray):
        data.train_mask = torch.from_numpy(data.train_mask).bool()
    elif not torch.is_tensor(data.train_mask):
        raise TypeError("train_mask must be a tensor or numpy array")

    # è·å–è®­ç»ƒèŠ‚ç‚¹çš„ç‰¹å¾ï¼ˆä»…è®­ç»ƒèŠ‚ç‚¹ç”¨äºèšç±»ï¼‰
    train_mask = data.train_mask  # ç°åœ¨æ˜¯ Tensor
    embedding = data.x[train_mask].detach().cpu().numpy()  # [n_train, dim]
    kmeans = KMeans(n_clusters=k, random_state=0)
    k_labels = kmeans.fit_predict(embedding)  # shape: [n_train]
    dataset = []
    train_indices = torch.where(train_mask)[0]  # âœ… ç°åœ¨ train_mask æ˜¯ Tensorï¼Œæ²¡é—®é¢˜ï¼
    for exclude in range(k):
        # mask: åœ¨è®­ç»ƒèŠ‚ç‚¹ä¸­ï¼Œä¸å±äº cluster `exclude` çš„èŠ‚ç‚¹
        mask = (k_labels != exclude)  # numpy array of bool, length = n_train
        mask = torch.from_numpy(mask)  # è½¬ä¸º Tensor
        # ä»è®­ç»ƒèŠ‚ç‚¹ä¸­é€‰å‡ºä¿ç•™çš„èŠ‚ç‚¹ï¼ˆå…¨å±€ç´¢å¼•ï¼‰
        sub_nodes_global = train_indices[mask]  # å…¨å±€èŠ‚ç‚¹ IDï¼ˆæ¥è‡ªå…¨å›¾ï¼‰
        # æ„å»ºå­å›¾ï¼ˆrelabel_nodes=True â†’ å±€éƒ¨ IDï¼‰
        sub_edge_index, _ = subgraph(sub_nodes_global, data.edge_index, relabel_nodes=True)
        # æ„é€ å­å›¾ Data å¯¹è±¡ï¼ˆä½¿ç”¨å±€éƒ¨ç‰¹å¾å’Œæ ‡ç­¾ï¼‰
        sub_data = Data(
            x=data.x[sub_nodes_global],
            edge_index=sub_edge_index,
            y=data.y[sub_nodes_global]
        )
        sub_data.orig_node_idx = sub_nodes_global  # ğŸ‘ˆ ä¿å­˜å…¨å±€ IDï¼
        dataset.append(sub_data)

    return dataset

# def create_cluster(data, k=7):
#     # ç±»è½¬å¯¼å­¦ä¹ ï¼šä¿ç•™å…¨é‡èŠ‚ç‚¹å’Œè¾¹ï¼Œä»…æŒ‰èšç±»åˆ’åˆ†æ ‡ç­¾
#     all_nodes = torch.arange(data.num_nodes, device=data.x.device)  # æ‰€æœ‰èŠ‚ç‚¹å¯è§
#     embedding = data.x.detach().cpu().numpy()  # ç”¨æ‰€æœ‰èŠ‚ç‚¹çš„ç‰¹å¾åšèšç±»ï¼ˆè€Œéä»…è®­ç»ƒèŠ‚ç‚¹ï¼‰
#
#     # èšç±»æ‰€æœ‰èŠ‚ç‚¹ï¼ˆåŒ…æ‹¬è®­ç»ƒå’Œæµ‹è¯•èŠ‚ç‚¹ï¼‰
#     kmeans = KMeans(n_clusters=k, random_state=42)
#     k_labels = kmeans.fit_predict(embedding)  # æ¯ä¸ªèŠ‚ç‚¹çš„èšç±»æ ‡ç­¾ï¼ˆ0~k-1ï¼‰
#
#     dataset = []
#     for cluster_id in range(k):
#         # å­å›¾è®­ç»ƒæ ‡ç­¾ï¼šæ’é™¤å½“å‰èšç±»ç°‡ï¼ˆç”¨å…¶ä»–ç°‡çš„æ ‡ç­¾è®­ç»ƒï¼‰
#         train_mask = torch.from_numpy(k_labels != cluster_id).to(data.x.device)
#         # å­å›¾éªŒè¯æ ‡ç­¾ï¼šä»…ç”¨å½“å‰èšç±»ç°‡ï¼ˆæ¨¡æ‹Ÿæœªæ ‡æ³¨èŠ‚ç‚¹ï¼‰
#         test_mask = torch.from_numpy(k_labels == cluster_id).to(data.x.device)
#
#         # æ„é€ åŒ…å«å…¨é‡èŠ‚ç‚¹å’Œè¾¹çš„å­å›¾ï¼ˆä»…æ ‡ç­¾åˆ’åˆ†ä¸åŒï¼‰
#         sub_data = Data(
#             x=data.x,  # å…¨é‡èŠ‚ç‚¹ç‰¹å¾ï¼ˆç±»è½¬å¯¼ï¼šæ‰€æœ‰èŠ‚ç‚¹å¯è§ï¼‰
#             edge_index=data.edge_index,  # å…¨é‡è¾¹ç»“æ„ï¼ˆç±»è½¬å¯¼ï¼šæ‰€æœ‰è¾¹å¯è§ï¼‰
#             y=data.y,  # å…¨é‡æ ‡ç­¾ï¼ˆä½†è®­ç»ƒæ—¶ä»…ç”¨train_maskéƒ¨åˆ†ï¼‰
#             train_mask=train_mask,
#             test_mask=test_mask
#         )
#         dataset.append(sub_data)
#     return dataset